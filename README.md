# â˜• Coffee Break: Scraper & NLP Project

Este proyecto es una herramienta de scraping y anÃ¡lisis de datos centrada en el pÃ³dcast cientÃ­fico **"Coffee Break: SeÃ±al y Ruido"**. Su propÃ³sito es extraer y estructurar metadatos clave (temas, timestamps, participantes, enlaces) de los episodios para su posterior anÃ¡lisis con tÃ©cnicas de procesamiento de lenguaje natural (NLP).

---

## ğŸ¯ Objetivos

- Extraer metadatos de cada episodio del sitio oficial.
- Estructurar temas y timestamps para consulta rÃ¡pida.
- Identificar y registrar los contertulios de cada episodio.
- Vincular referencias cientÃ­ficas y enlaces mencionados.
- Analizar el lenguaje utilizado mediante herramientas NLP.
- Preparar una base de datos reutilizable y expandible.

---

## ğŸš¦ Estado actual del proyecto

- [x] DefiniciÃ³n de estructura de carpetas
- [x] CreaciÃ³n de scaffolding automatizado (`scaffold.py`)
- [x] DiseÃ±o del pipeline general (`pipeline_steps.md`)
- [ ] Scraper de Ã­ndice de episodios
- [ ] Parsers de HTML para distintos formatos de episodio
- [ ] Sistema de base de datos (SQLite)
- [ ] IntegraciÃ³n de Whisper y diarizaciÃ³n
- [ ] AnÃ¡lisis NLP con spaCy
- [ ] CLI para automatizar tareas

---

## ğŸ“ Estructura del repositorio

```bash
coffee_scraper_project/
â”œâ”€â”€ scraping/               # Scrapers de HTML y parsers por tipo de episodio
â”œâ”€â”€ data/                   # HTML crudo, JSON estructurado, y audio
â”œâ”€â”€ database/               # SQLite o PostgreSQL
â”œâ”€â”€ nlp_pipeline/           # spaCy, Whisper, pyannote
â”œâ”€â”€ notebooks/              # ExploraciÃ³n y anÃ¡lisis visual
â”œâ”€â”€ tests/                  # Pruebas automatizadas
â”œâ”€â”€ cli.py                  # Entrada por lÃ­nea de comandos
â”œâ”€â”€ config.py               # ConfiguraciÃ³n global
â”œâ”€â”€ scaffold.py             # Script para crear estructura
â”œâ”€â”€ requirements.txt        # Dependencias
â””â”€â”€ README.md               # Este documento
```

---

## ğŸ› ï¸ InstalaciÃ³n y entorno

1. Crea un entorno conda o virtualenv:
```bash
conda create -n coffee_nlp python=3.10
conda activate coffee_nlp
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

3. (Opcional) Instala paquetes pesados para NLP/audio:
```bash
pip install spacy whisper pyannote.audio
```

---

## ğŸ§ª Comandos sugeridos (CLI futuro)

```bash
python cli.py download-index
python cli.py fetch-html --episode 505
python cli.py parse-episode --episode 505
python cli.py populate-db
python cli.py analyze --episode 505
```

---

## ğŸ¤– Dependencias clave

| Ãrea        | Herramientas                     |
|-------------|----------------------------------|
| Scraping    | `requests`, `beautifulsoup4`, `lxml` |
| Parsing     | `re`, `json`, `html.parser`     |
| NLP         | `spaCy`, `whisper`, `pyannote`   |
| DB          | `sqlite3`, `sqlalchemy` (futuro) |
| Utils       | `argparse`, `typer` (futuro)     |

---

## ğŸ“š Recursos relacionados
- Podcast oficial: https://seÃ±alyruido.com
- CÃ³digo del pipeline: [`pipeline_steps.md`](./pipeline_steps.md)
- HTML de ejemplo: ver `data/raw_html/ep505.html`

---

## âœ¨ Autor

Proyecto mantenido por [Miguel Di Lalla](https://github.com/MiguelDiLalla)

Â¿Comentarios o sugerencias? Â¡Haz un PR o abre una issue! ğŸš€

